{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ass 4 - Fill Missing Values using Imputation Methods.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "kzz7mGmumTS4",
        "guwmHhYsWfRI",
        "sYJWA7rPhE4j",
        "ht60gEzczTMU",
        "o7gWZAEHzXZh",
        "YPoTaFrizcGk",
        "hpjGVdVKzfeu"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Downloads and imports"
      ],
      "metadata": {
        "id": "kzz7mGmumTS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost --upgrade"
      ],
      "metadata": {
        "id": "d-KE5JUPa9ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas library\n",
        "import pandas as pd\n",
        "\n",
        "# import xgboos library\n",
        "import xgboost as xgb\n",
        "\n",
        "# import numpy packages\n",
        "import numpy as np\n",
        "from numpy import mean, std, nan\n",
        "\n",
        "# import sklearn packages\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import KNNImputer, IterativeImputer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# import xgb optimization packages \n",
        "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
        "\n",
        "# import functools to wrap the objective function\n",
        "from functools import partial"
      ],
      "metadata": {
        "id": "QDuyaFQNtsAC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(xgb.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOAWsM2nbK59",
        "outputId": "704bd27d-f7a5-4dbb-fbff-1a646bdef088"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download datasets\n",
        "!wget https://www.dropbox.com/s/tdm9uw248tuni9s/train.csv?dl=0 -O train.csv\n",
        "!wget https://www.dropbox.com/s/r26axzubyuexlsh/test.csv?dl=0 -O test.csv"
      ],
      "metadata": {
        "id": "3MGgXObMmYHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and prepare data"
      ],
      "metadata": {
        "id": "guwmHhYsWfRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_print_dataset(path):\n",
        "  \"\"\"\n",
        "    Loads the dataset into a dataframe from the given path and print the head of it.  \n",
        "    \n",
        "    Args:\n",
        "      path (str): local path to the required dataset\n",
        "\n",
        "    Return:\n",
        "      df (pd.Dataframe): dataframe of the dataset\n",
        "  \"\"\"\n",
        "  if path is not None:\n",
        "    df = pd.read_csv(path)\n",
        "    print(f\"The shape of the train_dataframe: {df.shape}\")\n",
        "    print()\n",
        "    pd.set_option('display.max_columns', 36)\n",
        "    pd.set_option('display.width', 180)\n",
        "    print(df.head())\n",
        "    return df"
      ],
      "metadata": {
        "id": "3YN12WQbzyuU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"train.csv\"\n",
        "train_df   = load_and_print_dataset(train_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHoTfvJMtjLx",
        "outputId": "7db9add1-9123-4e6f-c6e3-236b8a958bf7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the train_dataframe: (2000000, 36)\n",
            "\n",
            "   birth_year  birth_month  birth_time  birth_place  mother_age  marital_status  mother_education  father_age  father_education  interval_llb  cigarettes  mother_height  \\\n",
            "0        2017            5      1705.0          1.0          20             NaN               5.0        20.0               4.0         888.0         0.0           64.0   \n",
            "1        2017           10       442.0          1.0          38             1.0               5.0        61.0               7.0         107.0         0.0           61.0   \n",
            "2        2019            7      1453.0          1.0          29             1.0               5.0        29.0               3.0         888.0         0.0           63.0   \n",
            "3        2016           10       859.0          1.0          28             1.0               4.0        29.0               3.0         888.0         0.0           67.0   \n",
            "4        2019           10       817.0          1.0          24             2.0               4.0         NaN               NaN          36.0         0.0           68.0   \n",
            "\n",
            "   mother_bmi  pre_preg_weight  delivery_weight pre_preg_diabetes gest_diabetes pre_preg_hypertension gest_hypertension prev_preterm_birth infertility_treatment  prev_cesarian  \\\n",
            "0        33.0            192.0            203.0             False         False                 False             False              False                 False              0   \n",
            "1        20.8            110.0            133.0             False         False                 False             False              False                 False              0   \n",
            "2        23.9            135.0            162.0             False         False                 False             False              False                 False              0   \n",
            "3        29.3            187.0            222.0             False         False                 False             False              False                 False              0   \n",
            "4        38.0            250.0            251.0             False         False                  True             False              False                 False              0   \n",
            "\n",
            "  gonorrhea syphilis chlamydia hepatitis_b hepatitis_c labor_induction labor_augmentation steroids antibiotics chorioamnionitis anesthesia  apgar5  plurality  Female  \n",
            "0     False    False     False       False       False           False              False    False        True             True       True     9.0          1    True  \n",
            "1     False    False     False       False       False           False              False    False       False            False      False     9.0          1   False  \n",
            "2     False    False     False       False       False           False              False    False       False            False       True     9.0          1   False  \n",
            "3     False    False     False       False       False           False              False    False       False            False       True     9.0          1   False  \n",
            "4     False    False      True       False       False           False              False    False        True            False       True     9.0          1   False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = \"test.csv\"\n",
        "test_df   = load_and_print_dataset(test_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDMmLTqluAtg",
        "outputId": "161cf99b-050d-4876-97b9-51e80cf47593"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (15,16,17,18,19,20,22,23,24,25,26,27,28,29,30,31,32) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the train_dataframe: (2000000, 36)\n",
            "\n",
            "   birth_year  birth_month  birth_time  birth_place  mother_age  marital_status  mother_education  father_age  father_education  interval_llb  cigarettes  mother_height  \\\n",
            "0        2020            1      2354.0          1.0          22             2.0               5.0        27.0               NaN          18.0         0.0           56.0   \n",
            "1        2020            1       347.0          1.0          19             2.0               3.0        20.0               3.0          11.0         0.0           60.0   \n",
            "2        2020            1      1444.0          1.0          29             1.0               6.0        41.0               4.0          36.0         0.0           65.0   \n",
            "3        2020            1      1118.0          1.0          32             1.0               6.0        44.0               4.0         888.0         0.0           63.0   \n",
            "4        2020            1       654.0          1.0          25             1.0               3.0        25.0               4.0         888.0         0.0           66.0   \n",
            "\n",
            "   mother_bmi  pre_preg_weight  delivery_weight pre_preg_diabetes gest_diabetes pre_preg_hypertension gest_hypertension prev_preterm_birth infertility_treatment  prev_cesarian  \\\n",
            "0        21.3             95.0            118.0             False         False                 False             False              False                 False              0   \n",
            "1        34.4            176.0            161.0             False         False                 False             False              False                 False              0   \n",
            "2        24.1            145.0            184.0             False         False                 False             False              False                 False              0   \n",
            "3        28.7            162.0            160.0             False         False                 False             False              False                 False              0   \n",
            "4        35.2            218.0            233.0             False         False                 False             False              False                 False              0   \n",
            "\n",
            "  gonorrhea syphilis chlamydia hepatitis_b hepatitis_c labor_induction labor_augmentation steroids antibiotics chorioamnionitis anesthesia  apgar5  plurality  Female  \n",
            "0     False    False     False       False       False           False              False    False       False            False      False     8.0          1    True  \n",
            "1     False    False     False       False       False           False              False    False       False            False      False     9.0          1    True  \n",
            "2     False    False     False       False       False           False              False    False       False            False       True     7.0          2   False  \n",
            "3     False    False     False       False       False           False              False    False        True            False       True     9.0          1    True  \n",
            "4     False    False     False       False       False           False              False    False        True            False      False     9.0          1   False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df['apgar5'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np70aBAGQgIr",
        "outputId": "aab3c174-71b5-40e0-bf68-7bc6e02cb115"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 9.  8.  7.  4. 10.  6. nan  5.  2.  0.  1.  3.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of rows with missing values in train set: {train_df.shape[0] - train_df.dropna().shape[0]}. \\\n",
        "This is {(train_df.shape[0] - train_df.dropna().shape[0]) / train_df.shape[0] * 100:.2f} % of the data\")\n",
        "\n",
        "print(f\"Number of rows with missing values in test set: {test_df.shape[0] - test_df.dropna().shape[0]}. \\\n",
        "This is {(test_df.shape[0] - test_df.dropna().shape[0]) / test_df.shape[0] * 100:.2f} % of the data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1zRGliCzLaZ",
        "outputId": "6ec2d990-866d-4ff1-f722-32d96500c5e4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows with missing values in train set: 555199. This is 27.76 % of the data\n",
            "Number of rows with missing values in test set: 543120. This is 27.16 % of the data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols = train_df.select_dtypes(include=[\"object\"]).columns\n",
        "\n",
        "print(\"Amount of Nan for each categorical feature:\")\n",
        "print(train_df[cat_cols].isna().sum())\n",
        "print()\n",
        "print(\"Number of unique values in categorical features: \")\n",
        "print(train_df[cat_cols].nunique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enMMC-sp7Ufx",
        "outputId": "8f1d7803-71a4-46dc-abed-a93a81ab4da6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amount of Nan for each categorical feature:\n",
            "pre_preg_diabetes        1903\n",
            "gest_diabetes            1903\n",
            "pre_preg_hypertension    1903\n",
            "gest_hypertension        1903\n",
            "prev_preterm_birth       1903\n",
            "infertility_treatment    1903\n",
            "gonorrhea                5160\n",
            "syphilis                 5160\n",
            "chlamydia                5160\n",
            "hepatitis_b              5160\n",
            "hepatitis_c              5160\n",
            "labor_induction          1450\n",
            "labor_augmentation       1133\n",
            "steroids                 1133\n",
            "antibiotics              1133\n",
            "chorioamnionitis         1133\n",
            "anesthesia               1133\n",
            "dtype: int64\n",
            "\n",
            "Number of unique values in categorical features: \n",
            "pre_preg_diabetes        2\n",
            "gest_diabetes            2\n",
            "pre_preg_hypertension    2\n",
            "gest_hypertension        2\n",
            "prev_preterm_birth       2\n",
            "infertility_treatment    2\n",
            "gonorrhea                2\n",
            "syphilis                 2\n",
            "chlamydia                2\n",
            "hepatitis_b              2\n",
            "hepatitis_c              2\n",
            "labor_induction          2\n",
            "labor_augmentation       2\n",
            "steroids                 2\n",
            "antibiotics              2\n",
            "chorioamnionitis         2\n",
            "anesthesia               2\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can be seen that all the object columns have only 2 values (True or False) hence, in order to use XGBOOST we need to transform this into numbers and keep the nan values. For this, I transformed all the objects to float and validated that all nan values did not remove.  "
      ],
      "metadata": {
        "id": "a6MUmU9IQiry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[cat_cols]  = train_df[cat_cols].astype(\"float\")\n",
        "test_df[cat_cols]   = test_df[cat_cols].astype(\"float\")\n",
        "\n",
        "print(train_df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G02nxb-TNNEx",
        "outputId": "c45c5120-02e4-43ec-98e9-a37b22d313f3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000000 entries, 0 to 1999999\n",
            "Data columns (total 36 columns):\n",
            " #   Column                 Dtype  \n",
            "---  ------                 -----  \n",
            " 0   birth_year             int64  \n",
            " 1   birth_month            int64  \n",
            " 2   birth_time             float64\n",
            " 3   birth_place            float64\n",
            " 4   mother_age             int64  \n",
            " 5   marital_status         float64\n",
            " 6   mother_education       float64\n",
            " 7   father_age             float64\n",
            " 8   father_education       float64\n",
            " 9   interval_llb           float64\n",
            " 10  cigarettes             float64\n",
            " 11  mother_height          float64\n",
            " 12  mother_bmi             float64\n",
            " 13  pre_preg_weight        float64\n",
            " 14  delivery_weight        float64\n",
            " 15  pre_preg_diabetes      float64\n",
            " 16  gest_diabetes          float64\n",
            " 17  pre_preg_hypertension  float64\n",
            " 18  gest_hypertension      float64\n",
            " 19  prev_preterm_birth     float64\n",
            " 20  infertility_treatment  float64\n",
            " 21  prev_cesarian          int64  \n",
            " 22  gonorrhea              float64\n",
            " 23  syphilis               float64\n",
            " 24  chlamydia              float64\n",
            " 25  hepatitis_b            float64\n",
            " 26  hepatitis_c            float64\n",
            " 27  labor_induction        float64\n",
            " 28  labor_augmentation     float64\n",
            " 29  steroids               float64\n",
            " 30  antibiotics            float64\n",
            " 31  chorioamnionitis       float64\n",
            " 32  anesthesia             float64\n",
            " 33  apgar5                 float64\n",
            " 34  plurality              int64  \n",
            " 35  Female                 bool   \n",
            "dtypes: bool(1), float64(30), int64(5)\n",
            "memory usage: 536.0 MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Amount of Nan for each categorical feature:\")\n",
        "print(train_df[cat_cols].isna().sum())\n",
        "\n",
        "print(\"Amount of Nan for each categorical feature in test set:\")\n",
        "print(test_df[cat_cols].isna().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJQ0CBYN3udR",
        "outputId": "2df2152c-93bd-4d84-c6dc-2e9c935afce7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amount of Nan for each categorical feature:\n",
            "pre_preg_diabetes        1903\n",
            "gest_diabetes            1903\n",
            "pre_preg_hypertension    1903\n",
            "gest_hypertension        1903\n",
            "prev_preterm_birth       1903\n",
            "infertility_treatment    1903\n",
            "gonorrhea                5160\n",
            "syphilis                 5160\n",
            "chlamydia                5160\n",
            "hepatitis_b              5160\n",
            "hepatitis_c              5160\n",
            "labor_induction          1450\n",
            "labor_augmentation       1133\n",
            "steroids                 1133\n",
            "antibiotics              1133\n",
            "chorioamnionitis         1133\n",
            "anesthesia               1133\n",
            "dtype: int64\n",
            "Amount of Nan for each categorical feature in test set:\n",
            "pre_preg_diabetes        2115\n",
            "gest_diabetes            2115\n",
            "pre_preg_hypertension    2115\n",
            "gest_hypertension        2115\n",
            "prev_preterm_birth       2115\n",
            "infertility_treatment    2115\n",
            "gonorrhea                5689\n",
            "syphilis                 5689\n",
            "chlamydia                5689\n",
            "hepatitis_b              5689\n",
            "hepatitis_c              5689\n",
            "labor_induction          1152\n",
            "labor_augmentation       1152\n",
            "steroids                 1152\n",
            "antibiotics              1152\n",
            "chorioamnionitis         1152\n",
            "anesthesia               1152\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition, on the EDA phase I saw that multiple integer columns should also be categorical, for example: year, month etc. Therefore I added to the categorical features list more columns (can be seen below)."
      ],
      "metadata": {
        "id": "CCML2DnhRlMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.iloc[:, ~train_df.columns.isin(cat_cols)].nunique())\n",
        "print(train_df.iloc[:, ~train_df.columns.isin(cat_cols)].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmdCbX851f_3",
        "outputId": "59e8e4e1-e602-4abb-a0c4-ea0eca212105"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "birth_year             5\n",
            "birth_month           12\n",
            "birth_time          1440\n",
            "birth_place            7\n",
            "mother_age            39\n",
            "marital_status         2\n",
            "mother_education       8\n",
            "father_age            76\n",
            "father_education       8\n",
            "interval_llb         299\n",
            "cigarettes            61\n",
            "mother_height         45\n",
            "mother_bmi           560\n",
            "pre_preg_weight      301\n",
            "delivery_weight      301\n",
            "prev_cesarian          3\n",
            "apgar5                11\n",
            "plurality              5\n",
            "Female                 2\n",
            "dtype: int64\n",
            "   birth_year  birth_month  birth_time  birth_place  mother_age  marital_status  mother_education  father_age  father_education  interval_llb  cigarettes  mother_height  \\\n",
            "0        2017            5      1705.0          1.0          20             NaN               5.0        20.0               4.0         888.0         0.0           64.0   \n",
            "1        2017           10       442.0          1.0          38             1.0               5.0        61.0               7.0         107.0         0.0           61.0   \n",
            "2        2019            7      1453.0          1.0          29             1.0               5.0        29.0               3.0         888.0         0.0           63.0   \n",
            "3        2016           10       859.0          1.0          28             1.0               4.0        29.0               3.0         888.0         0.0           67.0   \n",
            "4        2019           10       817.0          1.0          24             2.0               4.0         NaN               NaN          36.0         0.0           68.0   \n",
            "\n",
            "   mother_bmi  pre_preg_weight  delivery_weight  prev_cesarian  apgar5  plurality  Female  \n",
            "0        33.0            192.0            203.0              0     9.0          1    True  \n",
            "1        20.8            110.0            133.0              0     9.0          1   False  \n",
            "2        23.9            135.0            162.0              0     9.0          1   False  \n",
            "3        29.3            187.0            222.0              0     9.0          1   False  \n",
            "4        38.0            250.0            251.0              0     9.0          1   False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "int_as_cat = [\"birth_year\", \"birth_month\", \"marital_status\", \"mother_education\", \"father_education\", \"Female\", \"plurality\", \"apgar5\", \"prev_cesarian\", \"birth_place\"]\n",
        "cat_cols   = list(cat_cols) + int_as_cat\n",
        "print(train_df.iloc[:, ~train_df.columns.isin(cat_cols)].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4uYll3j2QsA",
        "outputId": "6b0d7b6a-7b55-45c3-db68-b21a200da044"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   birth_time  mother_age  father_age  interval_llb  cigarettes  mother_height  mother_bmi  pre_preg_weight  delivery_weight\n",
            "0      1705.0          20        20.0         888.0         0.0           64.0        33.0            192.0            203.0\n",
            "1       442.0          38        61.0         107.0         0.0           61.0        20.8            110.0            133.0\n",
            "2      1453.0          29        29.0         888.0         0.0           63.0        23.9            135.0            162.0\n",
            "3       859.0          28        29.0         888.0         0.0           67.0        29.3            187.0            222.0\n",
            "4       817.0          24         NaN          36.0         0.0           68.0        38.0            250.0            251.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Auxiliary functions\n"
      ],
      "metadata": {
        "id": "sYJWA7rPhE4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_and_labels(dataframe):\n",
        "  \"\"\"\n",
        "  Split target column from the rest of the data\n",
        "  \n",
        "  Args:\n",
        "    dataframe (pd.Dataframe): data\n",
        "  \n",
        "  Returns:\n",
        "    data (pd.Dataframe): data columns\n",
        "    lables (np.array): labels\n",
        "  \"\"\"\n",
        "\n",
        "  data    = dataframe.copy()\n",
        "  labels  = data.pop(\"apgar5\")\n",
        "  assert (\"apgar5\" in data) == False\n",
        "  return data, labels"
      ],
      "metadata": {
        "id": "Dm32KnfCWkig"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_validation_training(train_data, model, imputer):\n",
        "  \"\"\"\n",
        "  Repeated stratified kfold cross validation\n",
        "\n",
        "  Args:\n",
        "    train_data (pd.Dataframe):\n",
        "    model (xgboost):\n",
        "    imputer (object):\n",
        "  \n",
        "  Returns:\n",
        "    mean_rmse (float)\n",
        "  \"\"\"\n",
        "  # define modeling pipeline\n",
        "  if imputer is None:\n",
        "    pipeline = Pipeline(steps = [('m', model)])\n",
        "  else:\n",
        "    pipeline = Pipeline(steps = [('i', imputer), ('m', model)])\n",
        "  \n",
        "  # split labels from train_data\n",
        "  X, y = get_data_and_labels(train_data)\n",
        "\n",
        "  # define model evaluation\n",
        "  cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=2, random_state=1)\n",
        "\n",
        "  # evaluate model\n",
        "  scores = -1 * cross_val_score(pipeline, X, y, \n",
        "                                scoring = \"neg_root_mean_squared_error\", \n",
        "                                cv = cv, \n",
        "                                error_score = 'raise'\n",
        "                                )\n",
        "  \n",
        "  print('Mean RMSE: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
        "  \n",
        "  mean_rmse = mean(scores)\n",
        "  return mean_rmse"
      ],
      "metadata": {
        "id": "QcVwP9z-hYTL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def full_train_and_test(train_data, test_data, model, imputer):\n",
        "  \"\"\"\n",
        "  Train XGBoost model on the whole dataset, and evaluate on the test set.\n",
        "\n",
        "  Args:\n",
        "    train_data (dataframe)\n",
        "    test_data  (dataframe)\n",
        "    model      (object)\n",
        "    imputer    (object)\n",
        "\n",
        "  Returns:\n",
        "    tuple: (rmse_train, rmse_test)\n",
        "  \"\"\"\n",
        "  \n",
        "  # define modeling pipeline\n",
        "  if imputer is None:\n",
        "    pipeline = Pipeline(steps = [('m', model)], verbose=True)\n",
        "  else:\n",
        "    pipeline = Pipeline(steps = [('i', imputer), ('m', model)])\n",
        "  \n",
        "  # split labels from train_data and test data\n",
        "  X_train, y_train = get_data_and_labels(train_data)\n",
        "  X_test, y_test   = get_data_and_labels(test_data)\n",
        "\n",
        "  # train model on training data\n",
        "  pipeline.fit(X_train, y_train)\n",
        "\n",
        "  # evaluate model on train and test data\n",
        "  y_train_pred = pipeline.predict(X_train)\n",
        "  y_test_pred  = pipeline.predict(X_test)\n",
        "\n",
        "  # calculate the rmse of train and test sets\n",
        "  rmse_train   = mean_squared_error(y_train, y_train_pred, squared = False)\n",
        "  rmse_test    = mean_squared_error(y_test, y_test_pred, squared = False)\n",
        "\n",
        "  print('RMSE train: %.3f, RMSE test: %.3f' % (rmse_train, rmse_test))\n",
        "  return (rmse_train, rmse_test)"
      ],
      "metadata": {
        "id": "xqJ2jaoPiGIG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(space, data, imputer):\n",
        "  \"\"\"\n",
        "  Objective function we want to minimize. In this case we want to minimize the RMSE.\n",
        "\n",
        "  Args:\n",
        "    space   (dict): dictionary of hyperparameter values\n",
        "    data    (pd.Dataframe): training data \n",
        "    imputer (object) \n",
        "  \"\"\"\n",
        "\n",
        "  clf = xgb.XGBRegressor(\n",
        "                  n_estimators      = space['n_estimators'], \n",
        "                  max_depth         = int(space['max_depth']), \n",
        "                  gamma             = space['gamma'],\n",
        "                  reg_alpha         = int(space['reg_alpha']),\n",
        "                  min_child_weight  = int(space['min_child_weight']),\n",
        "                  colsample_bytree  = int(space['colsample_bytree']),\n",
        "                  tree_method       = \"gpu_hist\", \n",
        "                  )\n",
        "  \n",
        "  rmse = cross_validation_training(data, clf, imputer)\n",
        "  \n",
        "  return {'loss': rmse, 'status': STATUS_OK }"
      ],
      "metadata": {
        "id": "zhUTjDX3lm6-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dictionary of XGBoost hyperparameters that should be tuned  \n",
        "space = {'max_depth':         hp.quniform(\"max_depth\", 3, 18, 1),\n",
        "        'gamma':              hp.uniform ('gamma', 1, 9),\n",
        "        'reg_alpha' :         hp.quniform('reg_alpha', 40, 180, 1),\n",
        "        'reg_lambda' :        hp.uniform('reg_lambda', 0, 1),\n",
        "        'colsample_bytree' :  hp.uniform('colsample_bytree', 0.5, 1),\n",
        "        'min_child_weight' :  hp.quniform('min_child_weight', 0, 10, 1),\n",
        "        'n_estimators':       180,\n",
        "        'seed':               0\n",
        "    }"
      ],
      "metadata": {
        "id": "ZVN5Yf3SxRPY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_optimization(train_data, max_iter=10, imputer=None):\n",
        "  \"\"\"\n",
        "  Use bayesian optimization with hyperopt to tune the hyperparameters of the XGBoost model.\n",
        "\n",
        "  Args:\n",
        "    train_data (dataframe)\n",
        "    max_iter   (int): number of iteration to run with different values\n",
        "    imputer    (object)\n",
        "\n",
        "  Returns:\n",
        "    best_hyperparams (dict): the hyperparameters which got the best results.\n",
        "  \"\"\"\n",
        "  \n",
        "  trials            = Trials()\n",
        "\n",
        "  # wrap the objective function to add more input parameters\n",
        "  fmin_objective    = partial(objective, \n",
        "                           data = train_data, \n",
        "                           imputer = imputer\n",
        "                           )\n",
        "  \n",
        "  # run optimization\n",
        "  best_hyperparams  = fmin(fn = fmin_objective,\n",
        "                          space = space,\n",
        "                          algo = tpe.suggest,\n",
        "                          max_evals = max_iter,\n",
        "                          trials = trials\n",
        "                           )\n",
        "  \n",
        "  # print different values used\n",
        "  print(\"hyperparameter values tested:\")\n",
        "  for trial in trials:\n",
        "    print(trial['misc']['vals'])\n",
        "\n",
        "  return best_hyperparams"
      ],
      "metadata": {
        "id": "rt2eUbTozwwj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dictionary to save the results\n",
        "results = {\n",
        "    \"strategy\": [],\n",
        "    \"rmse_train\": [],\n",
        "    \"rmse_test\": []\n",
        "}"
      ],
      "metadata": {
        "id": "J6s_wio5kggK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imputation Methods"
      ],
      "metadata": {
        "id": "VGJGLNt5ZsHm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. No imputation"
      ],
      "metadata": {
        "id": "ht60gEzczTMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_df.copy()\n",
        "test_data  = test_df.copy()\n",
        "\n",
        "train_rows = train_df.shape[0]\n",
        "test_rows  = test_df.shape[0]\n",
        "\n",
        "print(\"Train has %d rows, and Test has %d rows\" % (train_rows, test_rows))\n",
        "\n",
        "# remove rows with missing label\n",
        "train_data  = train_data.dropna(subset=[\"apgar5\"])\n",
        "test_data   = test_data.dropna(subset=[\"apgar5\"])\n",
        "\n",
        "new_train_rows  = train_data.shape[0]\n",
        "new_test_rows   = test_data.shape[0]\n",
        "\n",
        "print(\"Train has %d rows, and Test has %d rows after removing nan observations\" % (new_train_rows, new_test_rows))\n",
        "\n",
        "train_percent = (1 - new_train_rows / train_rows) * 100\n",
        "test_percent  = (1 - new_test_rows / test_rows) * 100\n",
        "\n",
        "print(\"Train percent removed: %.2f, Test percent removed:  %.2f\" % (train_percent, test_percent))"
      ],
      "metadata": {
        "id": "PpHhBgNIzWis",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5885efd-8b6d-46c3-f38b-67e22d94f288"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train has 2000000 rows, and Test has 2000000 rows\n",
            "Train has 1992138 rows, and Test has 1991820 rows after removing nan observations\n",
            "Train percent removed: 0.39, Test percent removed:  0.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_hyperparams = run_optimization(train_data, max_iter = 5)\n",
        "best_hyperparams[\"max_depth\"] = int(best_hyperparams[\"max_depth\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfqBRCa2y9BU",
        "outputId": "0e504b51-b0ba-4624-ac8a-1a0ec4d437dd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean RMSE: 0.806 (0.000)\n",
            "Mean RMSE: 0.806 (0.000)\n",
            "Mean RMSE: 0.806 (0.000)\n",
            "Mean RMSE: 0.806 (0.000)\n",
            "Mean RMSE: 0.806 (0.000)\n",
            "100%|██████████| 5/5 [04:46<00:00, 57.28s/it, best loss: 0.8061049912895687]\n",
            "hyperparameter values tested:\n",
            "{'colsample_bytree': [0.8819374383473955], 'gamma': [8.798774251417795], 'max_depth': [9.0], 'min_child_weight': [5.0], 'reg_alpha': [106.0], 'reg_lambda': [0.9337186873233942]}\n",
            "{'colsample_bytree': [0.984006653266161], 'gamma': [7.2714027171303535], 'max_depth': [15.0], 'min_child_weight': [8.0], 'reg_alpha': [146.0], 'reg_lambda': [0.060644806111325056]}\n",
            "{'colsample_bytree': [0.7942081724022483], 'gamma': [6.483893876534975], 'max_depth': [13.0], 'min_child_weight': [6.0], 'reg_alpha': [171.0], 'reg_lambda': [0.8905775954447839]}\n",
            "{'colsample_bytree': [0.9626004287890905], 'gamma': [5.54363237282062], 'max_depth': [15.0], 'min_child_weight': [9.0], 'reg_alpha': [99.0], 'reg_lambda': [0.49461851684470604]}\n",
            "{'colsample_bytree': [0.8699091284566327], 'gamma': [8.124458731163212], 'max_depth': [5.0], 'min_child_weight': [3.0], 'reg_alpha': [151.0], 'reg_lambda': [0.25360993989264724]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf   = xgb.sklearn.XGBRegressor(\n",
        "    tree_method = \"gpu_hist\", \n",
        "    **best_hyperparams\n",
        " )\n",
        "\n",
        "train_score, test_score = full_train_and_test(train_data, test_data, clf, None)\n",
        "\n",
        "results[\"rmse_train\"].append(train_score)\n",
        "results[\"rmse_test\"].append(test_score)\n",
        "results[\"strategy\"].append(\"No imputation\")"
      ],
      "metadata": {
        "id": "g0dvhs-616f_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "463ef703-f128-4b32-b3b7-df7dc3e7bd62"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pipeline] ................. (step 1 of 1) Processing m, total=   8.4s\n",
            "RMSE train: 0.798, RMSE test: 0.799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Drop rows with missing train_data"
      ],
      "metadata": {
        "id": "o7gWZAEHzXZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data  = train_df.copy()\n",
        "test_data   = test_df.copy()\n",
        "\n",
        "train_data  = train_data.dropna()\n",
        "test_data   = test_data.dropna()\n",
        "\n",
        "# validate that no more missing values\n",
        "assert train_data.isna().sum().sum()  == 0\n",
        "assert test_data.isna().sum().sum()   == 0"
      ],
      "metadata": {
        "id": "FFjjcWfDza73"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_hyperparams = run_optimization(train_data, max_iter = 5)\n",
        "best_hyperparams[\"max_depth\"] = int(best_hyperparams[\"max_depth\"])"
      ],
      "metadata": {
        "id": "iH38D75FwBpZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b13e42fc-4227-480d-b30b-e907614831fd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean RMSE: 0.769 (0.000)\n",
            "Mean RMSE: 0.769 (0.000)\n",
            "Mean RMSE: 0.769 (0.000)\n",
            "Mean RMSE: 0.769 (0.000)\n",
            "Mean RMSE: 0.769 (0.000)\n",
            "100%|██████████| 5/5 [03:05<00:00, 37.06s/it, best loss: 0.7685453039260338]\n",
            "hyperparameter values tested:\n",
            "{'colsample_bytree': [0.6816935225125191], 'gamma': [2.3530317249155575], 'max_depth': [7.0], 'min_child_weight': [3.0], 'reg_alpha': [54.0], 'reg_lambda': [0.6759086758600674]}\n",
            "{'colsample_bytree': [0.5250487643754203], 'gamma': [3.9792037378795797], 'max_depth': [16.0], 'min_child_weight': [5.0], 'reg_alpha': [160.0], 'reg_lambda': [0.16267151740961527]}\n",
            "{'colsample_bytree': [0.8825472808870545], 'gamma': [4.400889331551983], 'max_depth': [7.0], 'min_child_weight': [4.0], 'reg_alpha': [63.0], 'reg_lambda': [0.16421765474436045]}\n",
            "{'colsample_bytree': [0.820748338957688], 'gamma': [1.489200104759992], 'max_depth': [5.0], 'min_child_weight': [10.0], 'reg_alpha': [68.0], 'reg_lambda': [0.6723541787444508]}\n",
            "{'colsample_bytree': [0.6938236243065641], 'gamma': [7.72025716773312], 'max_depth': [10.0], 'min_child_weight': [5.0], 'reg_alpha': [107.0], 'reg_lambda': [0.10685927292131026]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf   = xgb.sklearn.XGBRegressor(\n",
        "    tree_method = \"gpu_hist\", \n",
        "    **best_hyperparams\n",
        " )\n",
        "\n",
        "train_score, test_score = full_train_and_test(train_data, test_data, clf, None)\n",
        "\n",
        "results[\"rmse_train\"].append(train_score)\n",
        "results[\"rmse_test\"].append(test_score)\n",
        "results[\"strategy\"].append(\"Drop rows\")"
      ],
      "metadata": {
        "id": "kFj9AUf8f5LH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f42f970c-5538-4672-c303-89d6046c98fb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pipeline] ................. (step 1 of 1) Processing m, total=   5.9s\n",
            "RMSE train: 0.762, RMSE test: 0.761\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Mean for continous, mode (most frequent) for categorical"
      ],
      "metadata": {
        "id": "YPoTaFrizcGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_df.copy()\n",
        "test_data  = test_df.copy()\n",
        "\n",
        "# calculate mean for continous and mode for categorical only on the train set\n",
        "train_con_mean = train_data.iloc[:, ~train_data.columns.isin(cat_cols)].mean()\n",
        "train_cat_mode =  train_data.iloc[:, train_data.columns.isin(cat_cols)].mode().iloc[0]\n",
        "\n",
        "# fill train set \n",
        "train_data.iloc[:, ~train_data.columns.isin(cat_cols)] = train_data.iloc[:, ~train_data.columns.isin(cat_cols)].fillna(train_con_mean)\n",
        "train_data.iloc[:, train_data.columns.isin(cat_cols)] = train_data.iloc[:, train_data.columns.isin(cat_cols)].fillna(train_cat_mode)\n",
        "\n",
        "# fill test set based on train set\n",
        "test_data.iloc[:, ~test_data.columns.isin(cat_cols)] = test_data.iloc[:, ~test_data.columns.isin(cat_cols)].fillna(train_con_mean)\n",
        "test_data.iloc[:, test_data.columns.isin(cat_cols)] = test_data.iloc[:, test_data.columns.isin(cat_cols)].fillna(train_cat_mode)\n",
        "\n",
        "assert train_data.isna().sum().sum() == 0\n",
        "assert test_data.isna().sum().sum()  == 0"
      ],
      "metadata": {
        "id": "TrQMud_YzfBf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_hyperparams = run_optimization(train_data, max_iter = 5)\n",
        "best_hyperparams[\"max_depth\"] = int(best_hyperparams[\"max_depth\"])"
      ],
      "metadata": {
        "id": "hppTbBGfz-ml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da279cee-38cd-4016-ff27-89b12783236e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean RMSE: 0.805 (0.000)\n",
            "Mean RMSE: 0.805 (0.000)\n",
            "Mean RMSE: 0.805 (0.000)\n",
            "Mean RMSE: 0.805 (0.000)\n",
            "Mean RMSE: 0.805 (0.000)\n",
            "100%|██████████| 5/5 [04:31<00:00, 54.25s/it, best loss: 0.8048680971853616]\n",
            "hyperparameter values tested:\n",
            "{'colsample_bytree': [0.606354636889247], 'gamma': [4.088860313315708], 'max_depth': [16.0], 'min_child_weight': [5.0], 'reg_alpha': [164.0], 'reg_lambda': [0.02605314349040977]}\n",
            "{'colsample_bytree': [0.6451216624639198], 'gamma': [5.037120888381173], 'max_depth': [4.0], 'min_child_weight': [6.0], 'reg_alpha': [160.0], 'reg_lambda': [0.40767742413659147]}\n",
            "{'colsample_bytree': [0.7636746656723454], 'gamma': [5.515774925772813], 'max_depth': [14.0], 'min_child_weight': [1.0], 'reg_alpha': [171.0], 'reg_lambda': [0.25400479023864175]}\n",
            "{'colsample_bytree': [0.6683348898446977], 'gamma': [6.716010290766364], 'max_depth': [8.0], 'min_child_weight': [3.0], 'reg_alpha': [75.0], 'reg_lambda': [0.10667315932414756]}\n",
            "{'colsample_bytree': [0.7474013559307646], 'gamma': [5.3554223865717905], 'max_depth': [18.0], 'min_child_weight': [6.0], 'reg_alpha': [100.0], 'reg_lambda': [0.5035861905485562]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf   = xgb.sklearn.XGBRegressor(\n",
        "    tree_method = \"gpu_hist\", \n",
        "    **best_hyperparams\n",
        " )\n",
        "\n",
        "train_score, test_score = full_train_and_test(train_data, test_data, clf, None)\n",
        "\n",
        "results[\"rmse_train\"].append(train_score)\n",
        "results[\"rmse_test\"].append(test_score)\n",
        "results[\"strategy\"].append(\"Mean & Mode\")"
      ],
      "metadata": {
        "id": "43dWDmIs0cih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d5f29d8-52a4-4289-f185-6336612fb92e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pipeline] ................. (step 1 of 1) Processing m, total=   8.4s\n",
            "RMSE train: 0.799, RMSE test: 0.798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Median for continous, mode (most frequent) for categorical"
      ],
      "metadata": {
        "id": "hpjGVdVKzfeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_df.copy()\n",
        "test_data  = test_df.copy()\n",
        "\n",
        "# calculate median for continous and mode for categorical only on the train set\n",
        "train_con_median = train_data.iloc[:, ~train_data.columns.isin(cat_cols)].median()\n",
        "train_cat_mode =  train_data.iloc[:, train_data.columns.isin(cat_cols)].mode().iloc[0]\n",
        "\n",
        "# fill train\n",
        "train_data.iloc[:, ~train_data.columns.isin(cat_cols)] = train_data.iloc[:, ~train_data.columns.isin(cat_cols)].fillna(train_con_median)\n",
        "train_data.iloc[:, train_data.columns.isin(cat_cols)] = train_data.iloc[:, train_data.columns.isin(cat_cols)].fillna(train_cat_mode)\n",
        "\n",
        "# fill test based on train\n",
        "test_data.iloc[:, ~test_data.columns.isin(cat_cols)] = test_data.iloc[:, ~test_data.columns.isin(cat_cols)].fillna(train_con_median)\n",
        "test_data.iloc[:, test_data.columns.isin(cat_cols)] = test_data.iloc[:, test_data.columns.isin(cat_cols)].fillna(train_cat_mode)\n",
        "\n",
        "assert train_data.isna().sum().sum() == 0\n",
        "assert test_data.isna().sum().sum()  == 0"
      ],
      "metadata": {
        "id": "49AHaqiXzg-A"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_hyperparams = run_optimization(train_data, max_iter = 5)\n",
        "best_hyperparams[\"max_depth\"] = int(best_hyperparams[\"max_depth\"])"
      ],
      "metadata": {
        "id": "rQKku1WYnCib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a33775a6-6fc5-41c2-b0c8-8f1b73fa2e3f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean RMSE: 0.805 (0.000)\n",
            "Mean RMSE: 0.805 (0.000)\n",
            "Mean RMSE: 0.805 (0.000)\n",
            "Mean RMSE: 0.805 (0.000)\n",
            "Mean RMSE: 0.805 (0.000)\n",
            "100%|██████████| 5/5 [04:47<00:00, 57.57s/it, best loss: 0.804944449463564]\n",
            "hyperparameter values tested:\n",
            "{'colsample_bytree': [0.5526238130458375], 'gamma': [3.5031571203351692], 'max_depth': [16.0], 'min_child_weight': [2.0], 'reg_alpha': [150.0], 'reg_lambda': [0.5557449654199064]}\n",
            "{'colsample_bytree': [0.5893982803801165], 'gamma': [8.63274052657396], 'max_depth': [13.0], 'min_child_weight': [8.0], 'reg_alpha': [71.0], 'reg_lambda': [0.24361167492016733]}\n",
            "{'colsample_bytree': [0.7739606829237153], 'gamma': [6.340247902739706], 'max_depth': [12.0], 'min_child_weight': [0.0], 'reg_alpha': [145.0], 'reg_lambda': [0.19984112887126848]}\n",
            "{'colsample_bytree': [0.9825973737933368], 'gamma': [4.455423960156235], 'max_depth': [3.0], 'min_child_weight': [3.0], 'reg_alpha': [69.0], 'reg_lambda': [0.7851383176193107]}\n",
            "{'colsample_bytree': [0.6117604225523685], 'gamma': [3.285635047064784], 'max_depth': [17.0], 'min_child_weight': [9.0], 'reg_alpha': [79.0], 'reg_lambda': [0.8065631380444851]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf   = xgb.sklearn.XGBRegressor(\n",
        "    tree_method = \"gpu_hist\", \n",
        "    **best_hyperparams\n",
        " )\n",
        "\n",
        "train_score, test_score = full_train_and_test(train_data, test_data, clf, None)\n",
        "\n",
        "results[\"rmse_train\"].append(train_score)\n",
        "results[\"rmse_test\"].append(test_score)\n",
        "results[\"strategy\"].append(\"Median & Mode\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5mVQ0i0B6rz",
        "outputId": "f4610e37-73b0-4be2-c407-f0956253d35e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pipeline] ................. (step 1 of 1) Processing m, total=   8.3s\n",
            "RMSE train: 0.797, RMSE test: 0.798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. KNN Imputation"
      ],
      "metadata": {
        "id": "_ASDMqESzhdB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the next two imputation methods I did not used CV and Hyperparameters optimiziation because the training time took too long. So, I just trained the models and showed the results."
      ],
      "metadata": {
        "id": "fr1pI3lfCYN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_df.copy()\n",
        "test_data  = test_df.copy()\n",
        "\n",
        "clf = xgb.sklearn.XGBRegressor(tree_method = \"gpu_hist\")\n",
        "\n",
        "# Categorical features cannot have an average hance I used 1 neighbor here\n",
        "imputer_cat = KNNImputer(n_neighbors = 1)\n",
        "imputer_cat.fit(train_data[cat_cols].iloc[:50000])\n",
        "train_data[cat_cols] = imputer_cat.transform(train_data[cat_cols])\n",
        "test_data[cat_cols]  = imputer_cat.transform(test_data[cat_cols])\n",
        "\n",
        "# Continous features can have an average distance hence I used more than 1 neighbor\n",
        "imputer_con     = KNNImputer(n_neighbors = 8, weights=\"uniform\")\n",
        "\n",
        "# get only continous data from train and test\n",
        "con_data_train  = train_data.iloc[:, ~train_data.columns.isin(cat_cols)]\n",
        "con_data_test   = test_data.iloc[:, ~test_data.columns.isin(cat_cols)]\n",
        "\n",
        "# fit on train based on the first 50,000 rows and then transform train and test\n",
        "imputer_con.fit(con_data_train.iloc[:50000])\n",
        "train_data.iloc[:, ~train_data.columns.isin(cat_cols)] = imputer_con.transform(con_data_train)\n",
        "test_data.iloc[:, ~test_data.columns.isin(cat_cols)]   = imputer_con.transform(con_data_test)\n",
        "\n",
        "# evaluate model\n",
        "train_score, test_score = full_train_and_test(train_data, test_data, clf, None)\n",
        "\n",
        "results[\"rmse_train\"].append(train_score)\n",
        "results[\"rmse_test\"].append(test_score)\n",
        "results[\"strategy\"].append(\"KNN method (k=8})\")"
      ],
      "metadata": {
        "id": "kIU5Kf1mzi4U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "790c9993-7042-40b5-b970-eff47e56ed68"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pipeline] ................. (step 1 of 1) Processing m, total=   4.3s\n",
            "RMSE train: 0.792, RMSE test: 0.801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Iterative Imputation"
      ],
      "metadata": {
        "id": "MlidW0J1zkOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_df.copy()\n",
        "test_data  = test_df.copy()\n",
        "\n",
        "clf  = xgb.XGBRegressor(tree_method = \"gpu_hist\")\n",
        "\n",
        "# init\n",
        "imputer = IterativeImputer(max_iter=10)\n",
        "\n",
        "# fit on train based on the first 50,000 rows and then transform train and test\n",
        "imputer.fit(train_data.iloc[:50000])\n",
        "train_data[train_data.columns] = imputer.transform(train_data)\n",
        "test_data[test_data.columns]   = imputer.transform(test_data)\n",
        "\n",
        "train_score, test_score = full_train_and_test(train_data, test_data, clf, None)\n",
        "\n",
        "results[\"rmse_train\"].append(train_score)\n",
        "results[\"rmse_test\"].append(test_score)\n",
        "results[\"strategy\"].append(\"Iterative imputer\")"
      ],
      "metadata": {
        "id": "cQe--g3Czl6z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cc1b5d1-28f8-4f01-8aab-b55e0a0c64d3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/impute/_iterative.py:701: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pipeline] ................. (step 1 of 1) Processing m, total=   4.4s\n",
            "RMSE train: 0.787, RMSE test: 0.795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparison"
      ],
      "metadata": {
        "id": "o62ovfz-gjjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comparison = pd.DataFrame(results).set_index(\"strategy\").rename(columns = {\"rmse_train\": \"RMSE Train\", \"rmse_test\": \"RMSE Test\"})\n",
        "comparison = comparison.round(3)\n",
        "\n",
        "# Highlighting the minimum values of last 2 columns\n",
        "comparison.style.highlight_min(color = 'green', axis = 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "uaX8tVfsgkkE",
        "outputId": "d1dcda9c-57a4-44ee-ce0b-354544fb1f7b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f9cd8d29610>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_0bc5e_row1_col0, #T_0bc5e_row1_col1 {\n",
              "  background-color: green;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_0bc5e_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >RMSE Train</th>\n",
              "      <th class=\"col_heading level0 col1\" >RMSE Test</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th class=\"index_name level0\" >strategy</th>\n",
              "      <th class=\"blank col0\" >&nbsp;</th>\n",
              "      <th class=\"blank col1\" >&nbsp;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_0bc5e_level0_row0\" class=\"row_heading level0 row0\" >No imputation</th>\n",
              "      <td id=\"T_0bc5e_row0_col0\" class=\"data row0 col0\" >0.798000</td>\n",
              "      <td id=\"T_0bc5e_row0_col1\" class=\"data row0 col1\" >0.799000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_0bc5e_level0_row1\" class=\"row_heading level0 row1\" >Drop rows</th>\n",
              "      <td id=\"T_0bc5e_row1_col0\" class=\"data row1 col0\" >0.762000</td>\n",
              "      <td id=\"T_0bc5e_row1_col1\" class=\"data row1 col1\" >0.761000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_0bc5e_level0_row2\" class=\"row_heading level0 row2\" >Mean & Mode</th>\n",
              "      <td id=\"T_0bc5e_row2_col0\" class=\"data row2 col0\" >0.799000</td>\n",
              "      <td id=\"T_0bc5e_row2_col1\" class=\"data row2 col1\" >0.798000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_0bc5e_level0_row3\" class=\"row_heading level0 row3\" >Median & Mode</th>\n",
              "      <td id=\"T_0bc5e_row3_col0\" class=\"data row3 col0\" >0.797000</td>\n",
              "      <td id=\"T_0bc5e_row3_col1\" class=\"data row3 col1\" >0.798000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_0bc5e_level0_row4\" class=\"row_heading level0 row4\" >KNN method (k=8})</th>\n",
              "      <td id=\"T_0bc5e_row4_col0\" class=\"data row4 col0\" >0.792000</td>\n",
              "      <td id=\"T_0bc5e_row4_col1\" class=\"data row4 col1\" >0.801000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_0bc5e_level0_row5\" class=\"row_heading level0 row5\" >Iterative imputer</th>\n",
              "      <td id=\"T_0bc5e_row5_col0\" class=\"data row5 col0\" >0.787000</td>\n",
              "      <td id=\"T_0bc5e_row5_col1\" class=\"data row5 col1\" >0.795000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    }
  ]
}